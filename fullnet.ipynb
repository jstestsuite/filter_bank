{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to get gauss1d working collumn 2\n",
    "#on the big space at the bottom row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "pi = math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"tiny-imagenet-200/wnids.txt\")\n",
    "count = 0\n",
    "yval = []\n",
    "for line in fh:\n",
    "    nl = ''\n",
    "    for e in line:\n",
    "        if e == '\\n':\n",
    "            break\n",
    "        else:\n",
    "            nl = nl+e\n",
    "    yval.append(nl)\n",
    "    #print(line)\n",
    "    count+=1\n",
    "fh.close()\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('tiny-imagenet-200/train')\n",
    "#list of folders\n",
    "t2 = os.listdir()\n",
    "#yval of list\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "#gets all x values... need to make y[200] oneshot array\n",
    "#change t2[:10] for all pics and change x size\n",
    "class_size = 200\n",
    "size = 500*class_size\n",
    "\n",
    "\n",
    "x = []\n",
    "y = np.zeros([size,class_size])\n",
    "c = 0\n",
    "c2 = 0\n",
    "for d in t2:\n",
    "    #print(d)\n",
    "    \n",
    "    for f2 in os.listdir(d+'/images'):\n",
    "        x.append(cwd+'\\\\'+d+'\\\\images\\\\'+f2)\n",
    "        y[c,c2] = 1\n",
    "        c = c+1\n",
    "        \n",
    "    c2+=1   \n",
    "        \n",
    "        #print(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"tiny-imagenet-200/val/val_annotations.txt\")\n",
    "count = 0\n",
    "yval = []\n",
    "yspot = []\n",
    "for line in fh:\n",
    "    nl = ''\n",
    "    nl2 = ''\n",
    "    for e in line:\n",
    "        if (e == '\\t'):\n",
    "            count +=1\n",
    "        elif (count ==0):\n",
    "            nl2 = nl2 +e\n",
    "        elif (count == 1): \n",
    "            nl = nl+e\n",
    "        elif count > 1: \n",
    "            break\n",
    "    yval.append(nl)\n",
    "    yspot.append(nl2)\n",
    "    #print(line)\n",
    "    count = 0\n",
    "fh.close()\n",
    "\n",
    "\n",
    "os.chdir('tiny-imagenet-200/train')\n",
    "#list of folders\n",
    "t3 = os.listdir()\n",
    "\n",
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "\n",
    "os.chdir('tiny-imagenet-200/val/images')\n",
    "#list of folders\n",
    "t2 = os.listdir()\n",
    "#yval of list\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "#gets all x values... need to make y[200] oneshot array\n",
    "#change t2[:10] for all pics and change x size\n",
    "class_size = 200\n",
    "size = 10000\n",
    "\n",
    "\n",
    "x = []\n",
    "y = np.zeros([size,class_size])\n",
    "c = 0\n",
    "c2 = 0\n",
    "for d in yspot:\n",
    "    #print(d)\n",
    "    \n",
    "    #for f2 in os.listdir(d+'/images'):\n",
    "    x.append(cwd+'\\\\'+d)\n",
    "    y[c, t3.index(yval[c])] = 1\n",
    "        #y[c,c2] = 1\n",
    "    c = c+1\n",
    "        \n",
    "   # c2+=1   \n",
    "        \n",
    "        #print(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "#os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(x[45001])\n",
    "print(np.nonzero(y[45001]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "ss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find where yval is in t2, then set y class as that\n",
    "\n",
    "x = []\n",
    "y = np.zeros([size,class_size])\n",
    "c = 0\n",
    "c2 = 0\n",
    "for d in yval:\n",
    "    #print(d)\n",
    "    \n",
    "    for f2 in os.listdir(d+'/images'):\n",
    "        x.append(cwd+'\\\\'+d+'\\\\images\\\\'+f2)\n",
    "        y[c,c2] = 1\n",
    "        c = c+1\n",
    "        \n",
    "    c2+=1   \n",
    "        \n",
    "        #print(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import argparse\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Cropping2D\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "#X_test = np.sum(X_test/3, axis=3, keepdims=True)\n",
    "def preprocess(img):\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_out= img.astype('float32')\n",
    "    #img_out=(img_out-img_out.mean())/img_out.std()\n",
    "    img_out=img_out/255\n",
    "    \n",
    "\n",
    "    return img_out\n",
    "\n",
    "def generator(x, y, batch_size=128):\n",
    "    num_samples = len(x)\n",
    "    x, y = shuffle(x, y)\n",
    "    while True:\n",
    "        images = []\n",
    "        angles = []\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            images = []\n",
    "            batch_y = y[offset:offset + batch_size]\n",
    "            batch_x = x[offset:offset + batch_size]\n",
    "            \n",
    "            for z in batch_x:\n",
    "                images.append(cv2.imread(z))\n",
    "            for h in batch_y:\n",
    "                angles.append(h)\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(batch_y)\n",
    "            X_train = preprocess(X_train)\n",
    "            \n",
    "            yield X_train, y_train\n",
    "\n",
    "train_generator = generator(x,y)\n",
    "\n",
    "ch, row, col = 3, 160, 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, l=next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=54, kernel_size=(3, 3), activation='relu', padding='same',input_shape=(64,64,3)))\n",
    "model.add(layers.MaxPooling2D())\n",
    "#model.add(layers.AveragePooling2D(input_shape=(32,32,12)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "#model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "#model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same',activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "#model.add(layers.Dense(units=4096, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=4096, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=2048, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=class_size, activation = 'softmax'))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=size/128,epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "with open('model.json', 'r') as f:\n",
    "    m = model_from_json(f.read())\n",
    "m.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = m.evaluate_generator(train_generator, steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = m.predict(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = cv2.imread(\"C:\\\\Users\\\\jstee\\\\Desktop\\\\udacity\\\\CarND-Traffic-Sign-Classifier-Project\\\\tiny-imagenet-200\\\\val\\\\images\\\\val_1496.JPEG\")\n",
    "temp3 = cv2.imread(\"C:\\\\Users\\\\jstee\\\\Desktop\\\\udacity\\\\CarND-Traffic-Sign-Classifier-Project\\\\tiny-imagenet-200\\\\train\\\\n03255030\\\\images\\\\n03255030_11.JPEG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3 = temp3.astype('float32')/255\n",
    "temp = temp.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = np.expand_dims(temp, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = np.empty([2,64,64,3])\n",
    "temp2[0,:,:,:] = temp\n",
    "temp2[1,:,:,:] = temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
